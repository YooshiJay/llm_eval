{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "from transformers.trainer_utils import set_seed\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers.generation import GenerationConfig\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "\n",
    "class args:\n",
    "    checkpoint_path = '/gemini/code/lamma3_eval/lamma3_model/8B'\n",
    "    eval_data_path = '/gemini/code/lamma3_eval/eval_data/gsm8k'\n",
    "    save_result_dir = \"/gemini/code/lamma3_eval/eval_result/gsm8k\"\n",
    "    # choices = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    debug = False\n",
    "    overwrite = False\n",
    "    batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = datasets.load_dataset(\"gsm8k\",'main')\n",
    "# dataset.save_to_disk(args.eval_data_path)\n",
    "\n",
    "dataset = load_from_disk(args.eval_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",\n",
       " 'answer': 'Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\\n#### 18'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_tokenizer():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.checkpoint_path,\n",
    "        # padding_side='left'\n",
    "    )\n",
    "\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\")\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        args.checkpoint_path,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=quantization_config\n",
    "    ).eval()\n",
    "    model.generation_config = GenerationConfig.from_pretrained(\n",
    "        args.checkpoint_path\n",
    "    )\n",
    "    model.generation_config.do_sample = False  # use greedy decoding\n",
    "    model.generation_config.repetition_penalty = 1.0  # disable repetition penalty\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:28<00:00,  7.23s/it]\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_models_tokenizer()\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_prompt = open(\"gsm8k_prompt.txt\").read()\n",
    "\n",
    "def doc_to_text(doc):\n",
    "    return (\n",
    "        fewshot_prompt\n",
    "        + \"\\nQuestion: \"\n",
    "        + doc[\"question\"]\n",
    "        + \"\\nLet's think step by step\\n\"\n",
    "    )\n",
    "\n",
    "def batch_process(func, *args):\n",
    "    print(f'args len: {len(args)}')\n",
    "    texts = args[0]  # 需要接受 dataset 完整的一/多行\n",
    "    assert type(texts) == datasets.arrow_dataset.Dataset, \"dataset 需要使用 select 取一个batch!\"\n",
    "    \n",
    "    text_ls = []\n",
    "    for i in range(len(texts)):\n",
    "        text_ls.append(func(texts[i]))\n",
    "\n",
    "    return text_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(model, tokenizer, input_txt):\n",
    "    input_ids = tokenizer(input_txt, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "    # context_enc = torch.tensor([input_ids]).to(model.device)\n",
    "    # print(f\"Input text: {input_txt}\\n\")\n",
    "    print(input_ids['input_ids'])\n",
    "    print(input_ids['attention_mask'])\n",
    "\n",
    "    outputs = model.generate(**input_ids, max_new_tokens = 200, eos_token_id = tokenizer.eos_token_id, pad_token_id = tokenizer.eos_token_id \n",
    "                             , repetition_penalty = 1.2, do_sample = False, temperature = 1.0, top_p = 1.0)\n",
    "    print(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args len: 1\n",
      "tensor([[128002, 128002, 128002,  ...,    555,   3094,    198],\n",
      "        [128002, 128002, 128002,  ...,    555,   3094,    198],\n",
      "        [128002, 128002, 128002,  ...,    555,   3094,    198],\n",
      "        ...,\n",
      "        [128000,  14924,     25,  ...,    555,   3094,    198],\n",
      "        [128002, 128002, 128002,  ...,    555,   3094,    198],\n",
      "        [128002, 128002, 128002,  ...,    555,   3094,    198]],\n",
      "       device='cuda:0')\n",
      "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')\n",
      "tensor([[128002, 128002, 128002,  ..., 128001, 128001, 128001],\n",
      "        [128002, 128002, 128002,  ..., 128001, 128001, 128001],\n",
      "        [128002, 128002, 128002,  ..., 128001, 128001, 128001],\n",
      "        ...,\n",
      "        [128000,  14924,     25,  ...,    220,   2031,   3346],\n",
      "        [128002, 128002, 128002,  ...,  39835,   5161,   6927],\n",
      "        [128002, 128002, 128002,  ..., 128001, 128001, 128001]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "context = batch_process(doc_to_text, dataset['test'].select(range(25,32)))\n",
    "completion = generate_sample(model, tokenizer, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Question: In 2004, there were 60 kids at a cookout. In 2005, half the number of kids came to the cookout as compared to 2004. In 2006, 2/3 as many kids came to the cookout as in 2005. How many kids came to the cookout in 2006?\n",
      "Let's think step by step\n",
      "In 2005, 60/2=30 kids came to the cookout.\n",
      "In 2006, 30/3*2=20 kids came to the cookout.\n",
      "The answer is 20\n",
      "\n",
      "Question: Zilla spent 7% of her monthly earnings on rent, half of it on her other monthly expenses, and put the rest in her savings. If she spent $133 on her rent, how much does she deposit into her savings account in a month?\n",
      "Let's think step by step\n",
      "Since $133 is equal to 7% of her earnings, then 1% is equal to $133/7 = $19.\n",
      "The total monthly earning of Zilla is represented by 100%, so $19 x 100 = $1900 is her monthly earnings.\n",
      "So, $1900/2 = $950 is spent on her other monthly expenses.\n",
      "The total amount spent on the rent and other monthly expenses is $133 + $950 = $1083.\n",
      "Hence, she saves $1900 - $1083 = $817 per month.\n",
      "The answer is 817\n",
      "\n",
      "Question: If Buzz bought a pizza with 78 slices at a restaurant and then decided to share it with the waiter in the ratio of 5:8, with Buzz's ratio being 5, what's twenty less the number of slices of pizza that the waiter ate?\n",
      "Let's think step by step\n",
      "The total ratio representing the slices of pizza that Buzz bought is 5+8=13\n",
      "If he shared the slices of pizza with the waiter, the waiter received a fraction of 8/13 of the total number of slices, which totals 8/13 * 78 = 48 slices\n",
      "Twenty less the number of slices of pizza that the waiter ate is 48-20 = 28\n",
      "The answer is 28\n",
      "\n",
      "Question: Jame gets a raise to $20 per hour and works 40 hours a week.  His old job was $16 an hour for 25 hours per week.  How much more money does he make per year in his new job than the old job if he works 52 weeks a year?\n",
      "Let's think step by step\n",
      "He makes 20*40=$800 per week\n",
      "He used to make 16*25=$400 per week\n",
      "So his raise was 800-400=$400 per week\n",
      "So he makes 400*52=$20,800 per year more\n",
      "The answer is 20800\n",
      "\n",
      "Question: Mr. Gardner bakes 20 cookies, 25 cupcakes, and 35 brownies for his second-grade class of 20 students. If he wants to give each student an equal amount of sweet treats, how many sweet treats will each student receive?\n",
      "Let's think step by step\n",
      "Mr. Gardner bakes a total of 20 + 25 + 35 = 80 sweet treats\n",
      "Each student will receive 80 / 20 = 4 sweet treats\n",
      "The answer is 4\n",
      "\n",
      "Question: A used car lot has 24 cars and motorcycles (in total) for sale. A third of the vehicles are motorcycles, and a quarter of the cars have a spare tire included. How many tires are on the used car lot’s vehicles in all?\n",
      "Let's think step by step\n",
      "The used car lot has 24 / 3 = 8 motorcycles with 2 tires each.\n",
      "The lot has 24 - 8 = 16 cars for sale\n",
      "There are 16 / 4 = 4 cars with a spare tire with 5 tires each.\n",
      "The lot has 16 - 4 = 12 cars with 4 tires each.\n",
      "Thus, the used car lot’s vehicles have 8 * 2 + 4 * 5 + 12 * 4 = 16 + 20 + 48 = 84 tires in all.\n",
      "The answer is 84\n",
      "\n",
      "Question: Norma takes her clothes to the laundry. She leaves 9 T-shirts and twice as many sweaters as T-shirts in the washer. When she returns she finds 3 sweaters and triple the number of T-shirts. How many items are missing?\n",
      "Let's think step by step\n",
      "Norma left 9 T-shirts And twice as many sweaters, she took 9 * 2= 18 sweaters\n",
      "Adding the T-shirts and sweaters, Norma left 9 + 18 = 27 clothes\n",
      "When she came back, she found 3 sweaters And triple the number of T-shirts, she found 3 * 3 = 9 T-shirts\n",
      "Adding the T-shirts and sweaters, Norma found 3 + 9 = 12 clothes\n",
      "Subtracting the clothes she left from the clothes she found, 27 - 12 = 15 clothes are missing\n",
      "The answer is 15\n",
      "\n",
      "Question: Adam has an orchard. Every day for 30 days he picks 4 apples from his orchard. After a month, Adam has collected all the remaining apples, which were 230. How many apples in total has Adam collected from his orchard?\n",
      "Let's think step by step\n",
      "During 30 days Adam picked 4 * 30 = 120 apples.\n",
      "So in total with all the remaining apples, he picked 120 + 230 = 350 apples from his orchard.\n",
      "The answer is 350\n",
      "\n",
      "Question: Gloria is shoe shopping when she comes across a pair of boots that fit her shoe budget. However, she has to choose between the boots and two pairs of high heels that together cost five dollars less than the boots. If one pair of heels costs $33 and the other costs twice as much, how many dollars are the boots?\n",
      "Let's think step by step\n",
      "One pair of heels costs $33 while another costs twice as much, i.e., $66.\n",
      "Gloria can buy either both pairs or just one pair of shoes since they don't match her foot size.\n",
      "She buys only one pair because buying them altogether would be too expensive.\n",
      "Therefore, she chooses between the boots and two pairs of high heels that together cost five dollars less than the boots.\n",
      "This means that the price difference between the boots and the chosen pair(s) of heels should be exactly $5.\n",
      "Now we know that the price of the boots is greater than the sum of prices of both pairs of heels ($99), but lower than their double ($132).\n",
      "We also know that the price difference between the boots and the chosen pair(s) of heels should be exactly $5.\n",
      "It follows that the price of the boots must be $110.\n",
      "\n",
      "Question: The average weight of three children is 50 pounds. One child weighs 10 pounds heavier than another child who weighs 70 percent\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "answer = tokenizer.decode(completion[-3], skip_special_tokens=False)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer(['123','jjds,cs fd'], padding=True, return_tensors=\"pt\")\n",
    "# tokenizer('<|end_of_text|>')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.checkpoint_path,\n",
    "        padding_side='left'\n",
    "    )\n",
    "tokenizer.pad_token_id = 128002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3295, 6100, 5053, 5759, 13448, 12979, 6828, 753, 3567, 3889]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = load_from_disk(\"/gemini/code/lamma3_eval/eval_data/mmlu/all\")\n",
    "print(len(dataset2['test']))\n",
    "\n",
    "# dataset2.select()\n",
    "\n",
    "\n",
    "random.sample(range(14042),10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
